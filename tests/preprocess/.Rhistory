feature_matrix <- add_feature(feature_matrix, frac_diff_vol,FUN = sd, name = "sd_frac_vol")
feature_matrix <- add_feature(feature_matrix, VHF,name="VHF")
feature_matrix <- add_feature(feature_matrix, DPO_close,name="DPO_close")
# split train set and test set
splited <- split_train_test(feature_matrix, train_size)
train_set <- data.frame(splited["train"])
colnames(train_set)[1] <- "label"
test_set <- data.frame(splited["test"])
colnames(test_set) <- names(train_set)
# predict by random forest
pred <- RF_pred(train_set, test_set)
acc <- cal_acc(pred_label=as.numeric(pred),
true_label=as.numeric(test_set$label))
print(paste0("accuracy is:", acc))
a <- 3
print(sprintf("aaa %s" % a))
print(sprintf("aaa %d" % a))
# hyper-parameters
CUMSUM_thres <- c(200,400,600,1000)
pt_sl <- c(1,1)
hold_time <- 200 # maximum holding time
target_return <- c(0.0001,0.005,0.05) # threshold for upper barrier and lower barrier
side <- NULL # use tripple barrier method
# for fractionally differentiated series
best_close_d <- 0.68
best_volume_d <- 0.68
thres_value <- 0.0001
for(i in 1:length(CUMSUM_thres)){
for(j in 1:length(target_return)){
single_CUMSUM_thres <- CUMSUM_thres[i]
single_target_rtn <- target_return[j]
# for train set/test set split
train_pct <- 2/3
train_size <- round(train_pct * nrow(all_data))
# data preparetion
close_price <- all_data$C
CUMSUM_filter_idx <- fmlr::istar_CUSUM(close_price, h=single_CUMSUM_thres)
feature_matrix <- meta_label_encap(close_price, CUMSUM_filter_idx,
pt_sl, single_target_rtn, hold_time,side)
# add new feature to feature matrix
frac_diff_close <- fracDiff(all_data$C,best_close_d,thres_value)
frac_diff_vol <- fracDiff(all_data$V,best_volume_d,thres_value)
DPO_close <-DPO(all_data$C)
VHF <- VHF(all_data$C)
feature_matrix <- add_feature(feature_matrix, frac_diff_close,name="dfrac_close")
feature_matrix <- add_feature(feature_matrix, frac_diff_vol,
FUN = sd, name = "sd_frac_vol")
feature_matrix <- add_feature(feature_matrix, VHF,name="VHF")
feature_matrix <- add_feature(feature_matrix, DPO_close,name="DPO_close")
# split train set and test set
splited <- split_train_test(feature_matrix, train_size)
train_set <- data.frame(splited["train"])
colnames(train_set)[1] <- "label"
test_set <- data.frame(splited["test"])
colnames(test_set) <- names(train_set)
# predict by random forest
pred <- RF_pred(train_set, test_set)
acc <- cal_acc(pred_label=as.numeric(pred),
true_label=as.numeric(test_set$label))
print(paste0("current CUMSUM thres is: ", single_CUMSUM_thres, "\n",
"current target return is: ", single_target_rtn, "\n",
"accuracy is:", acc,"\n",
"=========="))
}
}
# hyper-parameters
CUMSUM_thres <- c(200,400,600,1000)
pt_sl <- c(1,1)
hold_time <- 200 # maximum holding time
target_return <- c(0.0001,0.005,0.05) # threshold for upper barrier and lower barrier
side <- NULL # use tripple barrier method
# for fractionally differentiated series
best_close_d <- 0.68
best_volume_d <- 0.68
thres_value <- 0.0001
for(i in 1:length(CUMSUM_thres)){
for(j in 1:length(target_return)){
single_CUMSUM_thres <- CUMSUM_thres[i]
single_target_rtn <- target_return[j]
# for train set/test set split
train_pct <- 2/3
train_size <- round(train_pct * nrow(all_data))
# data preparetion
close_price <- all_data$C
CUMSUM_filter_idx <- fmlr::istar_CUSUM(close_price, h=single_CUMSUM_thres)
feature_matrix <- meta_label_encap(close_price, CUMSUM_filter_idx,
pt_sl, single_target_rtn, hold_time,side)
# add new feature to feature matrix
frac_diff_close <- fracDiff(all_data$C,best_close_d,thres_value)
frac_diff_vol <- fracDiff(all_data$V,best_volume_d,thres_value)
DPO_close <-DPO(all_data$C)
VHF <- VHF(all_data$C)
feature_matrix <- add_feature(feature_matrix, frac_diff_close,name="dfrac_close")
feature_matrix <- add_feature(feature_matrix, frac_diff_vol,
FUN = sd, name = "sd_frac_vol")
feature_matrix <- add_feature(feature_matrix, VHF,name="VHF")
feature_matrix <- add_feature(feature_matrix, DPO_close,name="DPO_close")
# split train set and test set
splited <- split_train_test(feature_matrix, train_size)
train_set <- data.frame(splited["train"])
colnames(train_set)[1] <- "label"
test_set <- data.frame(splited["test"])
colnames(test_set) <- names(train_set)
# predict by random forest
pred <- RF_pred(train_set, test_set)
acc <- cal_acc(pred_label=as.numeric(pred),
true_label=as.numeric(test_set$label))
print(cat("\n current CUMSUM thres is: ", single_CUMSUM_thres,
"\n current target return is: ", single_target_rtn,
"\n accuracy is:", acc,
"\n =========="))
}
}
# ROC curve
library(ROCR)
ROC <- prediction(as.numeric(predictions), test_set$label)
rm(list = setdiff(ls(), lsf.str()))
library(data.table)
root_path <- getwd() # dataset should be at the same directory of this script
file_name <- "unit_bar_XBTUSD_all.csv"
all_data<- read.csv(paste(root_path,file_name, sep='/'))
head(all_data)
cal_frac_weights <- function(d,thres_value,num_weights){
# this function is only used to calculate weights vector
w0 <- 1
if(!is.null(num_weights)){
# num_weights is not NULL
# possibly could use Reduce function to speed up
frac_weights <- rep(1,num_weights)
for(i in 2:num_weights){
frac_weights[i] <- frac_weights[i-1] * (-1) * (d-i+1)/i
}
}
else{
frac_weights <- 1
n <- 1
while (abs(frac_weights[n])>thres_value) {
tmp <- frac_weights[n] * (-1) * (d-n+1)/n
frac_weights <- c(frac_weights, tmp)
n <- n + 1
}
}
return(frac_weights)
}
fracDiff <- function(ts,d,thres_value,num_weights=NULL){
# @input: ts--vector
#   time series
# @input: d--double
# @input: thres_value--double
# @input: num_weights -- int
#   number of weights where we should cut off
#   default is NULL. if not NULL, then use thres_num instead of thres_value
# @output: stationary_ts -- vector
frac_weights <- cal_frac_weights(d,thres_value, num_weights)
N <- length(ts)
num_weights <- length(frac_weights)
if(num_weights>=N){stop('threshold is too small, please try to increase thres_value')}
stationary_ts <- rep(NA, N)# first length(ts)-length(frac_weights) elements are NA
stationary_ts[num_weights:N] <- sapply(num_weights:N, function(i){sum(ts[i:(i-num_weights+1)]*frac_weights)})
return(stationary_ts)
}
ts <- all_data$C
d <- 0.5 # Y_t = (1-B)^d X_t
thres_value <- 0.001
frac_diff <- fracDiff(ts,d,thres_value)
first_order_diff <- c(NA,diff(ts))
cut_point <- max(2, min(which(!is.na(frac_diff)))) # find the first non-NA element
N <- length(ts)
corr_1 <- cor(ts[cut_point:N],first_order_diff[cut_point:N])
corr_2 <- cor(ts[cut_point:N],frac_diff[cut_point:N])
print(paste0("correlation between original series and first order difference: ", corr_1))
print(paste0("correlation between original series and 0.5 fractional difference: ", corr_2))
library(ggplot2)
diff_compare <- data.frame("origin"=ts,"first_order"=first_order_diff,
"frac_diff"=frac_diff)
N <- length(ts)
ggplot(data=diff_compare,aes(1:N)) +
geom_line(aes(y=origin,colour="origin"))+
geom_line(aes(y=first_order,colour="first_order"),na.rm=TRUE) +
geom_line(aes(y=frac_diff,colour="frac_diff"),na.rm = TRUE) +
labs(title="Compare of origin series and differentiated series",
x ="time index", y = "close price") +
scale_color_manual(name="Line Color",
values = c(origin="red",
first_order="blue",
frac_diff="green"))
options(warn=-1)
library(VGAMextra)
library(ggplot2)
get_corr_p_val <- function(ts, d,thres_value, num_weights=NULL){
# this function is used to calculate two statistics of fractional differentiated series
# 1. correlation between frac_diff and ts
# 2. p-value of kpss test of frac_diff
# required library: library(VGAMextra)
# @input: ts--vector
#   time series
# @input: d--double
# @input: thres_value--double
# @input: num_weights -- int
#   number of weights where we should cut off
#   default is NULL. if not NULL, then use thres_num instead of thres_value
# @output: res -- vector
#   res[1]==correlation, res[2]==p-value
frac_diff <- fracDiff(ts, d,thres_value, num_weights)
res <- c(0,0)
# calculate correlation
N <- length(ts)
cut_point <- min(which(!is.na(frac_diff)))
res[1] <- cor(ts[cut_point:N],frac_diff[cut_point:N])
# calculate p-value
k <- KPSS.test(frac_diff[cut_point:N], type.H0 ="trend",show.output = FALSE)
res[2] <- k$pvalue
return(res)
}
find_best_d <- function(d_vec, p_val_vec,alpha=0.05){
# this function is used to find smallest d that could pass KPSS test
# i.e. make p-value > alpha
return(d_vec[min(which(p_val_vec>alpha))])
}
plot_corr_p_val <- function(d_vec, corr_vec, p_val_vec, title, subtitle){
# this function is used to plot the value of correlation and p-value
# with respect to different d
# required library: library(ggplot2)
# @input: d_vec --vector
# @input: corr_vec --vector
# @input: p_val_vec --vector
alpha <- 0.05 # when p_value > alpha we can't reject NULL hypothesis
plot_data <- data.frame("d"=d_vec, "correlation"=corr_vec, "p_value"=p_val_vec)
ggplot(data=plot_data,aes(x=d)) +
geom_line(aes(y = correlation, colour = "corr")) +
geom_line(aes(y = p_value, colour = "p_value")) +
geom_hline(aes(yintercept=alpha,colour="p-value=0.05"),
linetype="dashed",size=2) +
scale_y_continuous(sec.axis = sec_axis(~., name = "p value")) +
labs(y = "Correlation with origin series",x = "d",
title=paste0("correlation and p-value of KPSS test of ",title," series"),
subtitle=subtitle)
}
# split train set and test set
train_perc <- 2/3
train_size <- floor(train_perc * nrow(all_data))
# if sample train_data randomly, will get surpringly highly stationary time series
train_idx <- 1:train_size
train_data <- all_data[train_idx, ]
test_data <- all_data[-train_idx, ]
thres_value <- 0.0001
d_vec <- seq(from=0.02,to=1.0, by=0.02) # generate 50 d
close_ts <- train_data$C
plot_data <- sapply(1:length(d_vec),
function(i){return(get_corr_p_val(close_ts,d_vec[i],thres_value))})
corr_vec <- plot_data[1,]
p_values <- plot_data[2,]
# only used KPSS test for now, maybe add more test later
close_best_d <- find_best_d(d_vec, p_values)
close_subtitle <- paste0("the smallest d that could pass KPSS test is: ",close_best_d)
plot_corr_p_val(d_vec,corr_vec,p_values,
title="close",subtitle=close_subtitle)
volume_ts <- train_data$V
v_plot_data <- sapply(1:length(d_vec),
function(i){return(get_corr_p_val(volume_ts,d_vec[i],thres_value))})
v_corr_vec <- v_plot_data[1,]
v_p_values <- v_plot_data[2,]
# only used KPSS test for now, maybe add more test later
volume_best_d <- find_best_d(d_vec,v_p_values)
volume_subtitle <- paste0("the smallest d that could pass KPSS test is: ",volume_best_d)
plot_corr_p_val(d_vec,v_corr_vec,v_p_values,
title="volume",subtitle=volume_subtitle)
library(tseries)
frac_close <- fracDiff(close_ts,0.68,thres_value)
na_num <- min(which(!is.na(frac_close)))
tseries::pp.test(frac_close[(na_num+1):length(frac_close)])
frac_volume <- fracDiff(volume_ts,0.68,thres_value)
na_num <- min(which(!is.na(frac_volume)))
tseries::pp.test(frac_volume[(na_num+1):length(frac_volume)])
pt_sl <- c(1,1)
h <- 200 # maximum holding time, could also be a vector with same length as CUMSUM_filter_idx
target_return <- 0.005 # threshold for upper barrier and lower barrier
events <- data.frame(t0<-CUMSUM_filter_idx + 1,
t1<-CUMSUM_filter_idx + h,
trgt <- rep(target_return,length(CUMSUM_filter_idx)),
side <- rep(0,length(CUMSUM_filter_idx)))
library(fmlr)
close_price <- all_data$C
N <- length(close_price)
CUMSUM_filter_idx <- fmlr::istar_CUSUM(close_price, h=400)
plot(close_price)
title(main = paste0("Raw close price by CUMSUM filter\n num of events: ",
length(CUMSUM_filter_idx)))
abline(v=CUMSUM_filter_idx,lty = 2)
pt_sl <- c(1,1)
h <- 200 # maximum holding time, could also be a vector with same length as CUMSUM_filter_idx
target_return <- 0.005 # threshold for upper barrier and lower barrier
events <- data.frame(t0<-CUMSUM_filter_idx + 1,
t1<-CUMSUM_filter_idx + h,
trgt <- rep(target_return,length(CUMSUM_filter_idx)),
side <- rep(0,length(CUMSUM_filter_idx)))
out <- fmlr::label_meta(close_price, events, pt_sl,
ex_vert=T)# whether exclude event that hits vertical events or not
head(out)
sessionInfo()
library(ggplot2)
sessionInfo()
length(bar)
length(bars)
View(plot_data)
library(randomForestFML)
devtools::install_github("larryleihua/randomForestFML")
t1_Fea <- c(2,5,11)
t1 <- c(9,11,15)indMat <- getIndMat(t1_Fea, t1)
#' seqBoot(indMat)
t1_Fea <- c(2,5,11)
t1 <- c(9,11,15)indMat <- getIndMat(t1_Fea, t1)
seqBoot(indMat)
library(randomForestFML)
t1_Fea <- c(2,5,11)
t1 <- c(9,11,15)indMat <- getIndMat(t1_Fea, t1)
seqBoot(indMat)
t1_Fea <- c(2,5,11)
t1 <- c(9,11,15)
indMat <- getIndMat(t1_Fea, t1)
seqBoot(indMat)
intMat
indMat
rm(list=setdiff(ls(),lsf.str()))
a <- data.frame(x=c(1,2,3),y=c(3,4,5))
a
a <- cbind(y=c(3,4,5),a)
a
a <- subset(a,select=-c("y"))
a <- subset(a,select=-y)
a
min(3,4)
?randomeForestFML
feaMat <- data.frame(Y = c(1,1,0,1,0),
V = c(2,4,2,4,1),
t1Fea = c(2,5,8,14,20),
tLabel = c(4,12,16,23,38))
purged_k_CV(feaMat, k=2, gam=0.1)
library(fmlr)
purged_k_CV(feaMat, k=2, gam=0.1)
fmlr::purged_k_CV(feaMat, k=2, gam=0.1)
devtools::install_github("larryleihua/fmlr", force=T)
gc()
cat("ih", "itrgt", "iFold", "h", "trgt", "acc", "auc", "F1", "logloss",
"train:-1", "train:1", "test:-1", "test:1", "\n")
library(fmlr)
data <- read.csv("D:\fmlpy\tests\bar_test_data.csv")
data <- read.csv("D:\fmlpy\tests\bar_test_data.csv")
library(fmlr)
data <- read.csv("D:\\fmlpy\\tests\\bar_test_data.csv")
head(data)
fmlr::bar_time(data)
a<-fmlr::bar_time(data,1)
names(data)
names(data) <- c("time","price","vol")
a<-fmlr::bar_time(data,1)
library(lubridate)
class(data$time)
typeof(data$time)
data$time[1]
a <- as.numeric(data$time)
a[1]
a[2]
raw_data <- read.csv("D:\\fmlpy\\tests\\test_data.csv")
names(raw_data)
names(raw_data) <- c("Time", "Type", "OrderID", "Size", "Price", "Direction")
typeof(raw_data$Time)
class(raw_data$Time)
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
names(time_bar)
time_bar[1,]
head(time_bar)
time_bar[,1]
df <- data.frame(matrix(unlist(time_bar), nrow=length(time_bar), byrow=T))
head(df)
names(df)
names(df)
dim(df)
T(df)
a <- do.call(rbind.data.frame, time_bar)
a <- do.call(cbind.data.frame, time_bar)
names(a)
head(a)
plot(a$sec)
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
library(optparse)
install.packages("optparse")
library(optsparse)
library("optsparse")
library(optparse)
require(optparse)
a <- c(1,2,3)
a <- c(1,2,3);
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
source('D:/fmlpy_utili/gen_bars.R', echo=TRUE)
as.numeric("3s", units = "secs")
strptime(c("3s"), format = "%s", tz = "CET")
strptime(c("3s"), format = "%s", tz = "CET") - strptime(c("0s"), format = "%s", tz = "CET")
strptime(c("3m"), format = "%M", tz = "CET") - strptime(c("0s"), format = "%s", tz = "CET")
strptime(c("3m"), format = "%m", tz = "CET") - strptime(c("0s"), format = "%s", tz = "CET")
a <- "3s"
a[1]
length(a)
substr(a,1,2)
substr(a,1,1)
as.numberic(substr(a,1,1))
as.numeric(substr(a,1,1))
a <- "34s"
length(a)
strsplit(a, split)
strsplit(a, "s")
strsplit(a, "s")[1]
strsplit(a, "s")[1][1]
nchar(a)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
root_path <- getwd()
data_path <- paste(root_path,"bar_test_data.csv",sep = "/")
raw_data <- read.csv(data_path,header = F)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
lubridate::floor_date(useful_data$time[1])
useful_data$time[1]
raw_data$time[1]
raw_data$time[2]
raw_data$time[3]
setwd("D:fmlpy//tests//preprocess")
root_path <- getwd()
data_path <- paste(root_path,"bar_test_data.csv",sep = "/")
raw_data <- read.csv(data_path,header = F)
names(raw_data)
names(raw_data) <- c("time", "Price","Size")
setwd("D:fmlpy//tests//preprocess")
root_path <- getwd()
data_path <- paste(root_path,"bar_test_data.csv",sep = "/")
raw_data <- read.csv(data_path,header = T)
names(raw_data)
names(raw_data) <- c("time", "Price","Size")
raw_data$tStamp <- anytime(raw_data$time)
names(raw_data)
raw_data$tStamp[1]
lubridate::floor_date(useful_data$time[1])
raw_data$time[1]
lubridate::floor_date(useful_data$tStamp[1])
typeof(raw_data$tStamp[1])
min(raw_data$tStamp)
library(fmlr)
library(lubridate)
options(digits.secs=6)
root_path <- getwd()
file_name <- 'AMZN_2012-06-21_34200000_57600000_message_10.csv'
file_path <- paste(root_path, file_name, sep='/')
data <- read.csv(file_path, header = FALSE)
head(data)
options(warn=-1)
library(lubridate)
options(digits.secs=3)
names(data) <- c('Time', 'Type', 'Order_ID', 'Size', 'Price', 'Direction')
demodate <- '2012-06-21'
data$readableT <- as_datetime(demodate, tz="US/Eastern") + data$Time
head(data,n=5L)
executed_data <- data[data$Type %in% c(4,5),]
head(executed_data)
print(typeof(data$readableT[1]))
t0 <- lubridate::floor_date(data$readableT[1])
t0 <- lubridate::floor_date(data$readableT[1])
t0
print(class(data$readableT))
# t0 <- lubridate::floor_date(data$readableT[1])
# t0
print(class(raw_data$tStamp))
print(class(raw_data$tStamp[1]))
print(class(data$readableT[1]))
# t0 <- lubridate::floor_date(data$readableT[1])
# t0
winIdx <- as.factor(floor((raw_data$tStamp - raw_data$tStamp[1]) / 3))
winIdx[1]
winIdx
length(winInd)
length(winIx)
length(winIdx)
winIdx <- as.factor(floor((raw_data$tStamp - raw_data$tStamp[1]) / 100))
length(winIdx)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
winIdx[1]
winIdx[2]
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
winIdx <- as.factor(floor((useful_data$time - useful_data$time[1]) / 3))
length(levels(winIdx))
winIdx
useful_data$time[1]
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
useful_data$time[1]
winIdx <- as.factor(floor((useful_data$time - useful_data$time[1]) / 3))
length(levels(winIdx))
11419/3
winIdx <- as.factor(floor((useful_data$time - useful_data$time[1]) / 100))
length(levels(winIdx))
names(useful_data)
lubridate::floor_date(useful_data$time[1])
useful_data$time - lubridate::floor_date(useful_data$time[1])
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
source('D:/fmlpy/tests/preprocess/gen_bars.R', echo=TRUE)
